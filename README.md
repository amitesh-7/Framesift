# FrameSift ğŸ”

**FrameSift** is an AI-powered semantic video search engine that lets you find any moment in your videos using natural language queries.

> ğŸ¯ **Example**: Search _"a person walking a dog in the park"_ and get exact timestamps where that scene appears.

## ğŸ“‹ Table of Contents
- [Architecture Overview](#ï¸-architecture-overview)
- [Key Features](#-key-features)
- [Tech Stack](#ï¸-tech-stack)
- [How It Works](#-how-it-works)
- [Getting Started](#-getting-started)
- [API Documentation](#-api-documentation)
- [Project Structure](#-project-structure)
- [Configuration](#ï¸-configuration)
- [Troubleshooting](#-troubleshooting)
- [License](#-license)

---

## ğŸ—ï¸ Architecture Overview

FrameSift uses a **Hybrid AI Architecture** that balances performance, cost, and accuracy:

1. **Local Edge Processing (CPU)**: Fast, cost-effective filtering
2. **Cloud AI (GPU)**: Powerful deep learning for semantic understanding

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Upload Videoâ”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LOCAL PROCESSING (CPU)             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ 1. OpenCV Frame Extraction     â”‚  â”‚
â”‚  â”‚    - Motion-based filtering    â”‚  â”‚
â”‚  â”‚    - Skip static frames        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ 2. CLIP Semantic Filter        â”‚  â”‚
â”‚  â”‚    - Eliminate duplicates      â”‚  â”‚
â”‚  â”‚    - Keep unique scenes        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CLOUD PROCESSING (GPU)             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ 3. NVIDIA NIM Analysis         â”‚  â”‚
â”‚  â”‚    - Llama Vision (90B params) â”‚  â”‚
â”‚  â”‚    - Frame descriptions        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ 4. Vector Embeddings           â”‚  â”‚
â”‚  â”‚    - NV-Embed (4096-dim)       â”‚  â”‚
â”‚  â”‚    - Store in Pinecone         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ Search Ready! â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why Hybrid?**
- âœ… **70-80% cost reduction** - Process only unique frames
- âœ… **Faster processing** - Local filtering is instant
- âœ… **Better accuracy** - High-quality AI on important frames
- âœ… **Scalable** - Serverless infrastructure

---

## âœ¨ Key Features

### ğŸ¯ Semantic Search
- Natural language queries (e.g., "people dancing at a wedding")
- Top 5 most relevant results with confidence scores
- Click to jump to exact timestamp in video
- Full description display for each result

### ğŸ¬ Video Management
- Drag & drop upload with live progress
- Real-time processing status
- Automatic video storage and streaming
- Supports MP4, MOV, AVI, WebM

### ğŸ” Authentication & Security
- Google OAuth 2.0 integration
- Secure session management (Redis)
- Admin portal with user tracking
- **Auto cleanup** on logout

### ğŸ‘¨â€ğŸ’¼ Admin Dashboard
- Track all user logins
- Monitor user activity
- Protected with admin key
- View user profiles

### ğŸ“Š Real-time Feedback
Processing stages:
1. ğŸ“¤ Uploading video...
2. ğŸï¸ Extracting frames...
3. ğŸ¤– Analyzing with AI...
4. ğŸ’¾ Storing vectors...
5. âœ… Complete!

### ğŸ¨ Modern UI
- Responsive design
- Dark mode
- Glassmorphism effects
- Framer Motion animations

---

## ğŸ› ï¸ Tech Stack

### Frontend
| Technology | Version | Purpose |
|:-----------|:--------|:--------|
| React | 18.3 | UI framework |
| TypeScript | 5.6 | Type safety |
| Vite | 7.3 | Build tool |
| React Router | 6.x | Routing |
| Tailwind CSS | 3.4 | Styling |
| Framer Motion | 11.x | Animations |
| Zustand | 5.x | State management |
| @react-oauth/google | Latest | OAuth |
| Axios | 1.x | HTTP client |

### Backend
| Technology | Version | Purpose |
|:-----------|:--------|:--------|
| FastAPI | 0.115+ | Web framework |
| Python | 3.12 | Language |
| Uvicorn | Latest | ASGI server |
| PyMongo | Latest | MongoDB driver |
| Redis | Latest | Cache client |
| OpenCV | 4.x | Video processing |
| Transformers | Latest | CLIP model |

### Databases
| Service | Purpose |
|:--------|:--------|
| Pinecone | Vector database (4096-dim, cosine) |
| MongoDB Atlas | User data & tracking |
| Redis Cloud | Session cache (1hr TTL) |
| Local Storage | Video files |

### AI Models
| Model | Provider | Purpose | Size |
|:------|:---------|:--------|:-----|
| Llama 3.2 Vision Instruct | NVIDIA NIM | Frame analysis | 90B |
| NV-Embed v1 | NVIDIA NIM | Text embeddings | 4096-dim |
| CLIP ViT-B/32 | OpenAI (local) | Frame filtering | 151M |

---

## ğŸ¯ How It Works

### Video Processing Pipeline
```
Upload â†’ Save to backend/videos/ â†’ Create background job
   â†“
Extract frames (OpenCV, 1 fps)
   â†“
Filter by motion (skip static)
   â†“
CLIP semantic filtering (remove duplicates)
   â†“
NVIDIA Vision analysis (scene descriptions)
   â†“
Generate embeddings (NV-Embed, 4096-dim)
   â†“
Store in Pinecone (with metadata + timestamps)
   â†“
Ready for search!
```

### Search Flow
```
Query: "people playing basketball"
   â†“
Convert to vector (NV-Embed)
   â†“
Pinecone similarity search (cosine)
   â†“
Get top 5 matches with scores
   â†“
Display with timestamps
   â†“
Click â†’ Jump to moment
```

### Auto Cleanup on Logout
```
User logs out
   â†“
Clear Pinecone vectors
   â†“
Delete video files
   â†“
Clear Redis session
   â†“
Done!
```

---

## âš¡ Getting Started

### Prerequisites

**Required Software:**
- Node.js v18+ ([Download](https://nodejs.org/))
- Python 3.12 ([Download](https://www.python.org/downloads/))
- Git ([Download](https://git-scm.com/))

**Required API Keys:**
| Service | Purpose | Get It |
|:--------|:--------|:-------|
| NVIDIA NIM | AI models (need 2 keys) | [Get Keys](https://build.nvidia.com/) |
| Pinecone | Vector database | [Sign Up](https://www.pinecone.io/) |
| Google Cloud | OAuth | [Console](https://console.cloud.google.com/) |
| MongoDB Atlas | User storage | [Free Cluster](https://www.mongodb.com/cloud/atlas) |
| Redis Cloud | Caching | [Try Free](https://redis.com/try-free/) |

---

### ğŸš€ Quick Start

#### 1. Clone Repository
```bash
git clone https://github.com/your-username/framesift.git
cd framesift
```

#### 2. Backend Setup
```bash
cd backend

# Create virtual environment
python -m venv venv

# Activate it
# Windows:
.\venv\Scripts\Activate.ps1
# macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

Create `backend/.env.local`:
```env
# NVIDIA NIM (get from https://build.nvidia.com/)
NVIDIA_KEYS=["nvapi-key1", "nvapi-key2"]

# Pinecone
PINECONE_API_KEY=pcsk_xxxxxx
PINECONE_INDEX_NAME=framesift

# MongoDB Atlas
MONGODB_URI=mongodb+srv://user:pass@cluster.mongodb.net
MONGODB_DB_NAME=framesift
MONGODB_COLLECTION_NAME=users

# Redis Cloud
REDIS_URL=redis://default:password@host:port

# Admin (choose your secret)
ADMIN_KEY=your-secret-key
```

Start backend:
```bash
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

#### 3. Frontend Setup
```bash
# New terminal
cd frontend
npm install
```

Create `frontend/.env.local`:
```env
VITE_API_URL=http://localhost:8000
VITE_GOOGLE_CLIENT_ID=your-id.apps.googleusercontent.com
VITE_ADMIN_KEY=your-secret-key
VITE_ADMIN_EMAILS=admin@example.com
```

Start frontend:
```bash
npm run dev
```

#### 4. Setup Google OAuth

1. Go to [Google Cloud Console](https://console.cloud.google.com/)
2. Create project
3. Enable **Google+ API**
4. Create **OAuth 2.0 Client ID**
5. Add origins: `http://localhost:5173`
6. Copy Client ID to `.env.local`

#### 5. Setup Pinecone

1. [Pinecone Console](https://app.pinecone.io/)
2. Create index:
   - Name: `framesift`
   - Dimensions: `4096`
   - Metric: `cosine`
   - Plan: Serverless
3. Copy API key

#### 6. Test It!

1. Visit http://localhost:5173
2. Sign in with Google
3. Upload a test video
4. Wait for processing
5. Search: "what's in the video?"
6. Click result to jump to timestamp

---

## ğŸ“¡ API Documentation

### Video Processing
| Method | Endpoint | Description |
|:-------|:---------|:------------|
| GET | `/` | Health check |
| POST | `/upload` | Upload video for processing |
| GET | `/job/{id}` | Get processing status |
| POST | `/search` | Search query (returns top 5) |
| GET | `/jobs` | List all jobs |
| GET | `/videos/{id}` | Stream video file |

### Admin (Protected)
| Method | Endpoint | Description |
|:-------|:---------|:------------|
| POST | `/admin/track-login` | Track user login |
| GET | `/admin/users` | Get all users |
| POST | `/clear-database` | Clear all data on logout |

### Example: Upload Video
```bash
curl -X POST http://localhost:8000/upload \
  -F "file=@video.mp4"
```

Response:
```json
{
  "job_id": "abc-123",
  "video_id": "abc-123",
  "status": "processing"
}
```

### Example: Search
```bash
curl -X POST http://localhost:8000/search \
  -H "Content-Type: application/json" \
  -d '{
    "query": "people walking",
    "video_id": "abc-123",
    "top_k": 5
  }'
```

Response:
```json
{
  "results": [
    {
      "timestamp": 45.5,
      "description": "Two people walking in a park",
      "score": 0.92
    }
  ],
  "query": "people walking"
}
```

---

## ğŸ“‚ Project Structure

```
framesift/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                 # FastAPI app with all endpoints
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â”œâ”€â”€ videos/                 # Uploaded videos (auto-created)
â”‚   â”œâ”€â”€ .env.local              # Environment variables
â”‚   â””â”€â”€ venv/                   # Virtual environment
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ search/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ SearchPanel.tsx     # Search UI
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ VideoPlayer.tsx     # Video player
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ UploadModal.tsx     # Upload with progress
â”‚   â”‚   â”‚   â”œâ”€â”€ ui/                     # Reusable components
â”‚   â”‚   â”‚   â”œâ”€â”€ home/                   # Landing page
â”‚   â”‚   â”‚   â””â”€â”€ layout/                 # Layout components
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ Home.tsx                # Landing page
â”‚   â”‚   â”‚   â”œâ”€â”€ Search.tsx              # Search page
â”‚   â”‚   â”‚   â”œâ”€â”€ Admin.tsx               # Admin dashboard
â”‚   â”‚   â”‚   â”œâ”€â”€ Features.tsx            # Features page
â”‚   â”‚   â”‚   â”œâ”€â”€ HowItWorks.tsx          # How it works
â”‚   â”‚   â”‚   â””â”€â”€ Technology.tsx          # Tech stack
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ api.ts                  # Axios instance
â”‚   â”‚   â”‚   â””â”€â”€ videoService.ts         # Video API
â”‚   â”‚   â”œâ”€â”€ store/
â”‚   â”‚   â”‚   â””â”€â”€ authStore.ts            # Zustand auth
â”‚   â”‚   â””â”€â”€ App.tsx                     # Main app + routes
â”‚   â”œâ”€â”€ .env.local              # Environment variables
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â””â”€â”€ tsconfig.json
â”‚
â”œâ”€â”€ docker-compose.yml          # Docker orchestration
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## âš™ï¸ Configuration

### Backend Environment Variables
```env
# NVIDIA NIM (2 API keys required)
NVIDIA_KEYS=["key1", "key2"]

# Pinecone
PINECONE_API_KEY=pcsk_xxxxx
PINECONE_INDEX_NAME=framesift

# MongoDB
MONGODB_URI=mongodb+srv://...
MONGODB_DB_NAME=framesift
MONGODB_COLLECTION_NAME=users

# Redis
REDIS_URL=redis://...

# Admin
ADMIN_KEY=secret
```

### Frontend Environment Variables
```env
# Backend
VITE_API_URL=http://localhost:8000

# Google OAuth
VITE_GOOGLE_CLIENT_ID=xxxxx.apps.googleusercontent.com

# Admin
VITE_ADMIN_KEY=secret
VITE_ADMIN_EMAILS=admin@example.com
```

### Pinecone Index Configuration
- **Dimensions**: 4096 (NV-Embed v1)
- **Metric**: cosine
- **Cloud**: AWS (us-east-1 recommended)
- **Plan**: Serverless (free tier available)

### MongoDB Schema
```javascript
{
  email: String,
  name: String,
  picture: String,
  loginCount: Number,
  lastLogin: Date,
  firstLogin: Date
}
```

---

## ğŸ”§ Troubleshooting

### Frontend won't start
```bash
# Clear node_modules and reinstall
rm -rf node_modules package-lock.json
npm install
```

### Backend errors
```bash
# Check Python version
python --version  # Should be 3.12+

# Reinstall dependencies
pip install --upgrade -r requirements.txt
```

### Upload fails
- Check video format (MP4, MOV, AVI, WebM)
- Check file size (recommended < 500MB)
- Check backend logs for errors
- Verify NVIDIA API keys are valid

### Search returns no results
- Check Pinecone index exists
- Verify index dimensions (4096)
- Check video was fully processed
- Look for errors in job status

### Google OAuth fails
- Verify Client ID in `.env.local`
- Check authorized origins in Google Console
- Clear browser cache and cookies
- Add test users in OAuth consent screen

### Pinecone connection issues
- Verify API key is correct
- Check index name matches `.env`
- Ensure index is "Active" status
- Try deleting and recreating index

---

## ğŸ³ Docker Deployment

```bash
# Build and run
docker-compose up --build

# Run in background
docker-compose up -d

# Stop
docker-compose down

# View logs
docker-compose logs -f backend
docker-compose logs -f frontend
```

Access:
- Frontend: http://localhost:3000
- Backend: http://localhost:8000

---

## ğŸš€ Production Deployment

### Vercel (Frontend)
```bash
# Install Vercel CLI
npm i -g vercel

# Deploy
cd frontend
vercel --prod
```

### Railway/Render (Backend)
1. Push code to GitHub
2. Connect repository to Railway/Render
3. Add environment variables
4. Deploy

### Environment Variables
Make sure to set all `.env.local` variables in your deployment platform.

---

## ğŸ“ License

MIT License - see [LICENSE](LICENSE)

Built with â¤ï¸ by [Amitesh Vishwakarma](https://github.com/amitesh-7)

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing`)
5. Open Pull Request

---

## ğŸ“§ Support

- Issues: [GitHub Issues](https://github.com/your-username/framesift/issues)
- Email: amiteshvishwakarma2006@gmail.com
- Docs: [Full Documentation](https://framesift-docs.vercel.app)

---

## ğŸ¯ Roadmap

- [ ] Multi-user support with isolated databases
- [ ] Video sharing and collaboration
- [ ] Real-time collaborative search
- [ ] Mobile app (React Native)
- [ ] Advanced filters (date, duration, quality)
- [ ] Batch video processing
- [ ] Custom AI model training
- [ ] WebSocket for live updates

---

**â­ Star this repo if you find it useful!**
